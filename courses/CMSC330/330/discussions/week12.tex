\documentclass[12pt]{article}

  \usepackage{330-f12}

  \newcommand{\str}[1]{\emph{\textrm{#1}}}

  \newcommand{\mathstr}[1]{\ensuremath{\mathit{#1}}}

  \pagestyle{empty}

\begin{document}

  \header{\course}{Discussion section topics -- Week \#12}{\Term}

  \section{Discussion \#11, Friday, November 16}

    \subsection{Project \#4}

      Spend as much time discussing it and answering questions about it as
    needed.  If you don't get to all the material below it's fine.  (It can
    be finished later if time permits; the project is more important.)

    \subsection{Return Quiz \#4}

      Return the quizzes and go over the answers as needed, and answer any
    questions about the answers.  If there are problems that many students
    got wrong show how to solve them if time permits.  (If there's ever not
    enough time to go over all the answers when returning a quiz then just
    return them and encourage students to try to figure out what mistakes
    they made, and ask questions in office hours if needed.)

    %   Before returning the quizzes, if you still have any unreturned Quiz
    % \#1s, \textbf{staple them to the student's current quiz}, so if they
    % pick that one up they will get them both.  And keep bringing unclaimed
    % quizzes to subsequent discussion sections in case the students show up,
    % so you can give them back if so.

      Before returning the quizzes, make a strong effort to encourage anyone
    who didn't do that well (whatever the lower range of scores turns out to
    be) to come to office hours for extra help or explanation right away, so
    they can get caught up before they are even further behind.

      If any students didn't put their University ID number, TA's name, or
    discussion time, or any of these were wrong, please write a short note
    telling them they must put all their identifying information correctly.

    \subsection{Types of grammars}

      You can cover (or at least start) some parts of grammars that there
    isn't time to go over in lecture.  This is written in sort of an outline
    form.  If you can't finish it perhaps more can be done in subsequent
    discussions sections.

      (If you know about this material, note that my definition of regular
    grammars is a little simplified-- I only describe left--linear grammars,
    while right--linear grammars are also regular.  I thought this small
    inaccuracy made the definitions easier and was really not detrimental to
    the students' understanding of the important concepts.)

      (Unless you're prepared to write some slides or a handout about this
    material-- which is not necessary-- be sure students understand that
    there isn't going to be anything posted later about it, so they should
    be sure to take notes on the concepts during class.)

      Students should know that regular expressions, DFAs, and NFAs all
    recognize or describe the same class of languages, the regular
    languages. They also should know that context--free grammars generate
    more languages than the regular languages-- they saw a simple grammar
    can generate the language $a^{\mathrm{n}}b^{\mathrm{n}}$, which they
    should realize no regular expression, NFA, or DFA can recognize or
    describe.  They only know about context--free grammars, not the other
    types of grammars.

      Here's what to cover:

      \medskip

      Explain that restrictions on the form of productions
    $\mathrm{\alpha \, \rightarrow \, \beta}$
    affect the power of grammars.

    \vspace{-3mm}

    {

      \renewcommand{\arraystretch}{1.75}

      \begin{longtable}[t]
               {l@{\hspace{3mm}}l@{\hspace{9mm}}p{2.725in}@{\hspace{8mm}}
                p{1.85in}@{}}


        0.
          & unrestricted
          & $ \alpha, \beta \: $ can be any strings of terminals or
            nonterminals

          & \raggedright generate the most languages
          \tabularnewline

        1.
          & context--sensitive
          & same but $| \alpha | \le | \beta|$,
            or $\alpha$ is the start symbol and $\beta$ is $\epsilon$
          & \raggedright generate fewer languages
          \tabularnewline

        2.
          & context--free ($\equiv \:$ BNF)
          & $\alpha$ must be a single
            nonterminal
          & \raggedright generate even fewer languages
          \tabularnewline

        3.
          & regular
          & all productions are of one of the forms:

            \vspace{-3mm}

            \begin{multicols}{2}

              \hspace{3mm}
              \begin{grammar}
                \production{\alpha}{\mathstr{x}}
                \\
                \production{\alpha}{\epsilon}
                \\
              \end{grammar}

            \columnbreak

              \hspace{3mm}
              \begin{grammar}
                \production{\alpha}{\beta}
                \\
                \production{\alpha}{\mathstr{x}\beta}
                \\
              \end{grammar}

            \end{multicols}

            \vspace{-3mm}

            where $\alpha$ and $\beta$ are single nonterminals, and \str{x}
            is a string of one or more terminal symbols.

            In other words, the right--hand side of any production contains
            at most one nonterminal, which if present must be the rightmost
            symbol.

          & \raggedright generate the fewest languages
          \tabularnewline

      \end{longtable}

    }

    \vspace{-6mm}

    Examples of productions that couldn't be in a regular grammar (explain
    why):

    \begin{grammar}[1.5]
      \production{\mathrm{S}}{S\mathstr{b}S}
        \\

      \production{\mathrm{S}}{\mathstr{b}S\mathstr{b}}
        \\

    \end{grammar}

    (A grammar with these productions wouldn't be regular, but it could be
     context--free.)

    \smallskip

    The set of grammars at each level going upward can generate all the
    languages that the grammars at the lower levels can, and also more.

    As mentioned above, the students should realize some grammars are more
    powerful than (can generate languages that can't be recognized by)
    r.e.'s, DFAs, and NFAs.  Example: it's easy to see the the language
    \(
      \mathrm{
        \{
          {\mathstr{a}^n}{\mathstr{b}^n} \, \mid \, n \: \ge \: 0 \,
        \}
      }
    \)
    isn't regular, but can be generated by the simple context--free
    grammar
    \production{\mathrm{S}}
               {\mathrm{\mathstr{a}S\mathstr{b} \mid \epsilon}}
    shown in lecture.

    \subsubsection{The regular grammars and the regular languages}

      The regular grammars (of the most restricted form at level 3) generate
      the regular languages.

      What would we have to do to show this?

      \vspace{-1mm}

      \begin{enumerate}

        \addtolength{\itemsep}{-1mm}

        \item Show that any DFA can be converted to an equivalent regular
              grammar (generating the same langauge the DFA recognizes).

        \item Show that any regular grammar can be converted to an
              equivalent DFA.

      \end{enumerate}

      \vspace{-1mm}

      We'll show the first of these.  Given a DFA
      \(
        \mathrm{
          M \: = \: ( \Sigma, \: Q, \: {q_0}, \: F, \: \delta )
        }
      \),
      construct a regular grammar from it as follows.

      We will use nonterminal names in the grammar being constructed to
      represent states in the DFA we were given.

      We'll use productions in the grammar being constructed to represent
      transitions in the DFA.

      \pagebreak

      \begin{list}{}{}

        \item

          \begin{tabular}[t]{@{}p{3.8in}p{2.55in}@{}}

            \underline{For each component in the DFA of the form}
              & \underline{Add to the grammar}
              \\

          \end{tabular}

      \end{list}

      \medskip

      \enlargethispage{2mm}

      \begin{enumerate}

        \addtolength{\itemsep}{6mm}

        \item \begin{tabular}[t]{@{}p{3.8in}p{2.55in}@{}}

                \begin{automaton}(-5,0)(30,13)

                  \state[label=A](5,10){A}
                  \state[label=C](35,10){C}

                  \transition(A,\emph{b},C)

                \end{automaton}

                (where C is a nonfinal state)

              & The terminal symbol \str{b}, the nonterminal
                symbols A and C (if they haven't  already been added to the
                grammar), and the production 
                $\mathrm{A} \, \rightarrow \, \mathrm{\mathstr{b}C}$.

                Do this for all transitions of this form.

                Note that A can be a final or a nonfinal state.

              \end{tabular}

        \item \begin{tabular}[t]{@{}p{3.8in}p{2.55in}@{}}

                \begin{automaton}(-5,0)(30,13)

                  \state[label=A](5,10){A}
                  \state[final,label=C](35,10){C}

                  \transition(A,\emph{b},C)

                \end{automaton}

                (where C is a final state)

              & The productions
                \production{\mathrm{A}}
                           {\mathstr{b\mathrm{C} \midspc b}}

              \end{tabular}

        \item \begin{tabular}[t]{@{}p{3.8in}p{2.55in}@{}}

                \begin{automaton}(-5,0)(30,13)

                  \state[start,label=S](5,10){S}

                \end{automaton}

                (where S is a nonfinal state)

               & S as the start symbol.

               \end{tabular}

        \item \begin{tabular}[t]{@{}p{3.8in}p{2.55in}@{}}

                \begin{automaton}(-5,0)(30,13)

                  \state[start,final,label=S](5,10){S}

                \end{automaton}

                (where S is a final state)

              & The nonterminal $\mathrm{S'}$, the two productions
                $\mathrm{S'} \, \rightarrow \, \mathrm{S \midspc \epsilon}$,
                and $\mathrm{S'}$ as the start symbol.

              \end{tabular}

      \end{enumerate}

      If you do this to all the components of the DFA, what you'll wind up
      with is a grammar that:

      \vspace{-2mm}

      \begin{itemize}

        \addtolength{\itemsep}{-1mm}

        \item is regular, and

        \item generates the same language as the DFA recognizes or accepts.

      \end{itemize}

      \vspace{-1mm}

      To demonstrate equivalence, we would actually have to prove the
      grammar generates the same strings that the DFA recognizes.

      Example: L = the set of strings over
               $ \{ a, \: b \}^* $
               with an even number of \str{a}'s.

      \smallskip

      \begin{tabular}[t]{@{}p{3.5in}@{\hspace{10mm}}l@{}}

        A DFA accepting or recognizing this language:

        &

          \begin{automaton}(-5,10)(45,25)

            \state[label=E,final](5,10){E}
            \state[label=O](40,10){O}

            \transition[curved](E,\emph{a},O)
            \transition[labelposition=.85](E,\emph{b},E)
            \transition[curved](O,\emph{a},E)
            \transition(O,\emph{a},O)

          \end{automaton}

        \\

      \end{tabular}

      \pagebreak

      The grammar produced from this DFA using the procedure above, which
      generates the same language:

      \vspace{-2mm}

      \raggedcolumns

      \setlength{\columnsep}{14mm}

      \begin{multicols}{2}

        \hspace{4mm}
        \(
          \renewcommand{\arraystretch}{1.5}
          \begin{array}{l@{\hspace{12mm}}l}
  
            \production{\mathrm{E}'}{\mathrm{E \midspc \epsilon}}
              & \textrm{rule (4)}
              \\
  
            \production{\mathrm{E}}{\mathrm{\mathstr{a}O}}
              & \textrm{rule (1)}
              \\
  
            \production{\mathrm{O}}{\mathrm{\mathstr{b}O}}
              & \textrm{rule (1)}
              \\
  
            \production{\mathrm{O}}{\mathrm{\mathstr{a}E \midspc \mathstr{a}}}
              & \textrm{rule (2)}
              \\
  
            \production{\mathrm{E}}{\mathrm{\mathstr{b}E \midspc \mathstr{b}}}
              & \textrm{rule (2)}
              \\
  
          \end{array}
        \)

      \columnbreak

        Rewriting:
  
        \hspace{4mm}
        \begin{grammar}[1.5]
            \production{\mathrm{E}'}{\mathrm{E \midspc \epsilon}}
            \\
  
            \production{\mathrm{E}}{\mathrm{\mathstr{a}O \midspc \mathstr{b}E
                                    \midspc \mathstr{b}}}
            \\
  
            \production{\mathrm{O}}{\mathrm{\mathstr{b}O \midspc
                                    \mathstr{a}E \midspc \mathstr{a}}}
            \\
  
        \end{grammar}
  
      \end{multicols}

      \vspace{-1mm}

      \begin{itemize}

        \addtolength{\itemsep}{-.5mm}

        \item Point out how all the productions follow the form of a regular
              grammar.

        \item This algorithm or construction is guaranteed to produce an
              grammar that is regular and unambiguous from a DFA.

        \item Note the construction is not unique (since grammars aren't
              unique)-- other regular grammars can generate the same
              language.

        \item Question-- will the opposite construction work directly? If
              not, why not? (What about a grammar with productions like
              \production{A}{\mathstr{x}A \midspc \mathstr{x}B \midspc
              \mathstr{x}C}?  Also what if the grammar doesn't have a
              production for every nonterminal beginning with every terminal
              symbol-- following the construction as is wouldn't produce a
              DFA.)  Of course these problems can be handled (the inverse
              transformation is possible, just more complex).  How could
              some of these problems be addressed?

      \end{itemize}

    \subsubsection{Context--sensitive grammar example}

      An example of a context--sensitive grammar, one that generates the
      language
      \(
        \mathrm{
          \{ \,
            {\mathstr{a}^n}{\mathstr{b}^n}{\mathstr{c}^n} \midspc
            n \: \ge \: 1 \,
          \}
        }
      \)%
      :

      \hspace{10mm}\begin{grammar}[1.5]
        \production{S}{\mathstr{a}SBC \midspc \mathstr{ab}C}
        \\

        \production{CB}{BC}
        \\

        \production{\mathstr{b}B}{\mathstr{bb}}
        \\

        \production{\mathstr{b}C}{\mathstr{bc}}
        \\

        \production{\mathstr{c}C}{\mathstr{cc}}
        \\

      \end{grammar}

      \medskip

      (Point out why it's not context--free.)

      In a context--sensitive or unrestricted grammar, left sides of
      productions can have:

      \vspace{-1mm}

      \begin{itemize}

        \addtolength{\itemsep}{-1.5mm}

        \item terminals

        \item more than one nonterminal

      \end{itemize}

      \vspace{-1mm}

      When using a context--sensitive grammar, if you find the entire
      left--hand side of any production somewhere in a sentential form in a
      derivation, you can replace it with the right--hand side.  Example-- a
      derivation A derivation for \str{aabbcc} in the grammar above:

      \vspace{-6mm}

      \begin{eqnarray*}
        \mathrm{\underline{S}}
          & \ \Longrightarrow \
          & \mathrm{\mathstr{a}\underline{S}BC \ \Longrightarrow \
                    \mathstr{aab}\underline{CB}C \ \Longrightarrow \
                    \mathstr{aa}\underline{\mathstr{b}B}CC \
                    \Longrightarrow \
                    \mathstr{aab}\underline{\mathstr{b}C}C \
                    \Longrightarrow
                    \mathstr{aabb}\underline{\mathstr{c}C} \
                    \Longrightarrow \ \mathstr{aabbcc}
            }
            \\
      \end{eqnarray*}

      \vspace{-5mm}

      It could be shown that this language is not regular and is not
      context--free (no r.e.\ or DFA or NFA could recognize it and no CFG
      could generate it).  It can only be generated with a
      context--sensitive or an unrestricted grammmar.

      More powerful grammars (unrestricted or context--sensitive grammars)
      could describe more programming language syntax than context--free
      grammars, but they are not practical to use.

\end{document}
