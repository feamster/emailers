
\newpage \setcounter{page}{1}
\lfoot{\fancyplain{Printed: \today}{Nick Feamster}}
\cfoot{\fancyplain{Revised: March 8, 2007}{Research Statement}}
\rfoot{Page \thepage}

\begin{center}

{\Large\textbf{Research Statement}}\\[.1in] {\large\textbf{Nick
Feamster}}\\[.05in] feamster@cc.gatech.edu \\
http://www.cc.gatech.edu/$\sim$feamster/ \\[.1in] \end{center}



%XXX what's the big problem ? XXX
Today's network operators face a major challenge: spam, phishing, denial
of service attacks, and even the increasing size and complexity of the
network itself have made the network increasingly difficult to
manage. At the same time, everyday users are becoming more dependent on
the Internet: even minutes of downtime can result in inconvenience or
loss for users and companies.  Nobody notices when the network works
well, but everyone suffers when it doesn't.  My research focuses on
developing tools and algorithms that make the network easier to manage,
more secure, and more available.

%% Network operations---techniques, algorithms, and protocols to help users
%% and network operators run networks better---is becoming an increasingly
%% important problem area as the applications users are running over the
%% network (e.g., telephony, streaming video, games, banking) place
%% increasingly more stringent demands on network performance, security,
%% and availability.  The network is also growing: by some estimates, the
%% number of end systems on the Internet has increased five-fold (to 500
%% million) over the past six years.  This growth is a testament to the
%% Internet's huge success, but it is also exposing the Internet's
%% shortcomings.  Spam continues to grow and, by some estimates, comprises
%% 90\% of all email traffic.  Phishing attacks remain a persistent threat,
%% with anywhere from 30,000 to 50,000 new phishing Web sites coming online
%% every month.  Availability remains at two-and-a-half ``nines'': nearly
%% two days of downtime per year. 

I have tackled a variety of problems in network operations ranging from
real-time network diagnosis to stemming unwanted traffic like spam to
architectures for fast failure recovery.  Many people---most notably,
operators ``in the trenches''---are also working on these problems.
Unfortunately, many of the people who have the domain knowledge that
best equip them to solve these problems are busy with day-to-day
operations, putting out fires as they arise but rarely taking time to
think about fundamental changes to the network that might eradicate
these problems.  My research fills this gap.  I first devise methods to
understand the nature of the problem in practice.  I then tackle
domain-specific problems with tools and techniques from other
disciplines---ranging from machine learning to economics to program
analysis---whose principles might provide insights into a new,
previously undiscovered solution.  I then devise a new approach or
solution, and I transfer it to practice through implementation and
deployment of real-world systems.


I have applied my research approach to defend the network against
unwanted traffic, such as spam.  Prior to my work, nearly all previous
approaches to filtering spam relied in some way on analyzing an email's
contents to determine the legitimacy of the message.  This approach,
content filtering, continues to improve dramatically, and many people
are working on tuning content filters.  Nevertheless, the approach has a
fundamental shortcoming: email content is malleable, meaning that it is
very easy for a spammer to alter the content of an email to evade a
filter without changing the actual meaning of the message.  To keep pace
with continually changing content, both operators and implementors of
spam filters must continually tune their filters in a game of catch-up.
For example, last year saw a rise in spam whose main content was
transported in images; when content filters incorporated optical
character recognition for these image-based messages, spammers switched
to portable document format (PDF) messages.  My research has taken a
complementary approach: rather than classifying an email message based
on {\em what} is in the message, classify the message based on {\em how
it is sent} (e.g., what country it coming from, when it was sent).  In
other words, examine the {\em network-level behavior} of the email
sender and classify the spam based on whether the observed sending
behavior likely corresponds to a legitimate sender or a spammer.  Based
on my study of network-level behavior of spammers, which received the
Best Student Paper Award at {\em ACM SIGCOMM} in 2006, I have developed
a new class of blacklisting techniques, called {\em behavioral
blacklisting}, which leverages machine learning algorithms to classify
email senders as spammers based on previously observed spamming
patterns.  I am presently working with both Ironport and Secure
Computing, vendors of several large spam filtering appliances, to deploy
and evaluate these algorithms in practice.

I have also developed several new techniques that improve Internet
availability by helping operators run their networks better.  Much of my
work has focused on fault detection and troubleshooting.  Prior to my
work, operators relied on detecting problems with networks ``at
runtime'' on a live network.  My work demonstrated that, in fact, many
routing problems could be detected simply by examining the configuration
of the routing protocols, before the configuration is even deployed.  I
applied techniques from static program analysis to routing configuration
to help network operators catch mistakes and predict dynamic network
behavior before the configurations are deployed on a live network,
preventing costly and catastrophic network downtime. The work's
cornerstone is a system called ``rcc'' (router configuration checker),
which received the Best Paper Award at {\em ACM/USENIX Networked Systems
Design and Implementation (NSDI)} in 2005 and has been used by hundreds
of Internet Service Providers (ISPs) around the world to check their
network configurations for errors.  Beyond predicting behavior and
proactively detecting configuration faults, operators need to understand
the network's behavior as it is running (e.g., to detect equipment
failures, attacks, or unplanned shifts in network traffic).
Unfortunately, operators are drowning in a sea of heterogeneous data,
none of which intuitively points them to the true source of the problem.
To help operators better understand network ``at runtime'', I
have applied unsupervised learning techniques to Internet routing data
to help them efficiently mine the data for network events that require
corrective action.  We are applying these detection algorithms
to routing data in several large ISPs and enterprise networks.

Two of the Internet's most pressing problems, availability and security,
have been around since its inception.  They are the most difficult to
solve because they require making the network easier to manage and
operate.  Breakthroughs will require domain knowledge, application of
techniques from a wide range of areas, and 
implementation of the resulting solutions in working systems that are
ultimately deployed in practice.  I believe my approach to research will
allow me to continue to make important contributions to these areas.
